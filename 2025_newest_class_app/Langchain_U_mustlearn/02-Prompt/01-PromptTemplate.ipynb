{"cells":[{"cell_type":"markdown","metadata":{"id":"WM95b3r-VWtf"},"source":["# 提示模板\n","## 概述\n","本教學涵蓋如何使用 ```LangChain``` 建立和使用提示模板。\n","提示模板對於生成動態且靈活的提示至關重要，能夠滿足各種使用情境，如對話歷史記錄、結構化輸出和專門查詢。\n","在本教學中，我們將探索建立 ```PromptTemplate``` 物件的方法、應用部分變數、透過 YAML 檔案管理模板，以及利用進階工具如 ```ChatPromptTemplate``` 和 ```MessagePlaceholder``` 來增強功能。\n","\n","### 目錄\n","- [概述](#概述)\n","- [環境設定](#環境設定)\n","- [建立 PromptTemplate 物件](#建立prompttemplate物件)\n","- [使用 partial_variables](#使用partial_variables)\n","- [從 YAML 檔案載入提示模板](#從yaml檔案載入提示模板)\n","- [ChatPromptTemplate](#chatprompttemplate)\n","- [MessagePlaceholder](#messageplaceholder)\n","\n","### 參考資料\n","- [LangChain Documentation : Prompts](https://python.langchain.com/api_reference/core/prompts.html#)\n","\n","---\n","\n","## 我的見解\n","\n","提示模板是 LangChain 生態系統的基礎組件，它讓開發者能夠建立可重用、動態的提示，大幅提高了 AI 應用開發的效率和一致性。\n","\n","## 學習補充重點\n","\n","**提示模板的核心價值：**\n","- **可重用性**：一次建立，多處使用，減少重複程式碼\n","- **動態性**：支援變數替換，適應不同的輸入情境\n","- **結構化**：清晰的模板結構便於維護和除錯\n","- **標準化**：確保整個應用中提示的一致性\n","\n","**主要組件功能：**\n","\n","**PromptTemplate：**\n","- 基礎的文字模板，支援變數插值\n","- 適合簡單的單輪對話或查詢場景\n","- 提供輸入驗證和格式化功能\n","\n","**partial_variables：**\n","- 允許預設部分變數值\n","- 適用於有固定元素的模板（如系統資訊、日期等）\n","- 提高模板的靈活性和可配置性\n","\n","**YAML 檔案管理：**\n","- 將提示邏輯與程式碼分離\n","- 便於非技術人員編輯和維護\n","- 支援版本控制和團隊協作\n","\n","**ChatPromptTemplate：**\n","- 專為多輪對話設計\n","- 支援系統、使用者、助手等不同角色\n","- 更適合複雜的對話式 AI 應用\n","\n","**MessagePlaceholder：**\n","- 動態插入訊息序列\n","- 特別適合處理對話歷史記錄\n","- 支援靈活的訊息結構\n","\n","**實際應用場景：**\n","- **客服機器人**：標準化的問答模板\n","- **內容生成**：部落格文章、產品描述等格式化內容\n","- **資料分析**：結構化的分析報告模板\n","- **教育應用**：個人化的學習內容生成\n","\n","**最佳實務建議：**\n","- 設計模板時考慮變數的命名規範\n","- 使用部分變數來設定常用的預設值\n","- 將複雜的提示分解為可組合的子模板\n","- 定期審查和優化模板的效果\n","\n","**進階技巧：**\n","- 結合條件邏輯建立動態模板\n","- 使用模板繼承減少重複程式碼\n","- 實施模板版本管理和 A/B 測試\n","- 建立模板庫以促進團隊共享\n","\n","提示模板是構建可維護、可擴展 AI 應用的關鍵工具，掌握其使用方法對於 LangChain 開發者來說至關重要。"]},{"cell_type":"markdown","metadata":{"id":"UKt2ztpAVWtg"},"source":["## Environment Setup\n","\n","Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n","\n","**[Note]**\n","- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n","- You can check out the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mastmuM3VWtg","outputId":"999b5939-1e97-4c82-e73f-e192132b91ec"},"outputs":[{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 24.1 -> 24.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["%%capture --no-stderr\n","%pip install langchain-opentutorial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dg5i8oABVWth"},"outputs":[],"source":["# Install required packages\n","from langchain_opentutorial import package\n","\n","package.install(\n","    [\n","        \"langsmith\",\n","        \"langchain\",\n","        \"langchain_core\",\n","        \"langchain_community\",\n","        \"langchain_openai\",\n","    ],\n","    verbose=False,\n","    upgrade=False,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RuJxDRC8VWth","outputId":"c82196d9-aa11-47e4-d388-325ea7cc3345"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["from dotenv import load_dotenv\n","\n","load_dotenv(override=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkmwbFmEVWth","outputId":"c3d94c7c-c51e-45ee-9c1d-9b3a1702c434"},"outputs":[{"name":"stdout","output_type":"stream","text":["Environment variables have been set successfully.\n"]}],"source":["# Set environment variables\n","from langchain_opentutorial import set_env\n","\n","set_env(\n","    {\n","        # \"OPENAI_API_KEY\": \"\",\n","        # \"LANGCHAIN_API_KEY\": \"\",\n","        \"LANGCHAIN_TRACING_V2\": \"true\",\n","        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n","        \"LANGCHAIN_PROJECT\": \"Prompt-Template\",\n","    }\n",")"]},{"cell_type":"markdown","metadata":{"id":"Xq2PGhaIVWth"},"source":["Let's setup ```ChatOpenAI``` with ```gpt-4o``` model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUByBq2jVWth"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","# Load the model\n","llm = ChatOpenAI(model_name=\"gpt-4o\")"]},{"cell_type":"markdown","metadata":{"id":"7zSEwfReVWth"},"source":["## 建立 ```PromptTemplate``` 物件\n","有兩種方式可以建立 ```PromptTemplate``` 物件。\n","- 1. 使用 ```from_template()``` 方法\n","- 2. 一次性建立 ```PromptTemplate``` 物件和提示\n","\n","---\n","\n","## 我的見解\n","\n","這兩種建立方法提供了不同層次的靈活性，開發者可以根據具體需求選擇最適合的方式。\n","\n","## 學習補充重點\n","\n","**方法一：```from_template()``` 方法**\n","- **優點**：簡潔快速，適合簡單的模板建立\n","- **適用場景**：原型開發、簡單應用、快速測試\n","- **特點**：自動推斷變數，減少配置工作\n","\n","**範例應用：**\n","```python\n","from langchain.prompts import PromptTemplate\n","\n","# 簡單直接的方式\n","template = \"告訴我關於 {topic} 的 {details}\"\n","prompt = PromptTemplate.from_template(template)\n","```\n","\n","**方法二：完整物件建立**\n","- **優點**：完全控制，支援進階配置\n","- **適用場景**：複雜應用、需要詳細配置的模板\n","- **特點**：明確指定輸入變數、輸出解析器等\n","\n","**範例應用：**\n","```python\n","# 完整配置的方式\n","prompt = PromptTemplate(\n","    input_variables=[\"topic\", \"details\"],\n","    template=\"告訴我關於 {topic} 的 {details}\",\n","    # 可以添加更多配置選項\n","    validate_template=True\n",")\n","```\n","\n","**選擇建議：**\n","- **快速原型**：使用 ```from_template()```\n","- **生產環境**：考慮完整物件建立以獲得更好的控制\n","- **團隊開發**：明確的變數定義有助於程式碼可讀性\n","- **複雜邏輯**：需要額外配置時選擇完整建立方式\n","\n","**進階技巧：**\n","- 結合兩種方法的優勢\n","- 使用工廠模式管理不同類型的模板\n","- 實施模板驗證和錯誤處理機制"]},{"cell_type":"markdown","metadata":{"id":"O4dEJad0VWti"},"source":["### Method 1. Using the ```from_template()``` method\n","\n","- Define template with variable as ```{variable}``` ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sczoqg3MVWti","outputId":"e9cf2e4a-20ff-41aa-a714-a3302a20cbf4"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.prompts import PromptTemplate\n","\n","# Define template. In this case, {country} is a variable\n","template = \"What is the capital of {country}?\"\n","\n","# Create a `PromptTemplate` object using the `from_template` method\n","prompt = PromptTemplate.from_template(template)\n","prompt"]},{"cell_type":"markdown","metadata":{"id":"7h-ANwQLVWti"},"source":["You can complete the prompt by assigning a value to the variable ```country``` ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VMABOGKAVWti","outputId":"30840482-c8f3-4ad9-f67b-a248955484d6"},"outputs":[{"data":{"text/plain":["'What is the capital of United States of America?'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Create prompt. Assign value to the variable using `format` method\n","prompt = prompt.format(country=\"United States of America\")\n","prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xMt4NVUeVWti"},"outputs":[],"source":["# Define template\n","template = \"What is the capital of {country}?\"\n","\n","# Create a `PromptTemplate` object using the `from_template` method\n","prompt = PromptTemplate.from_template(template)\n","\n","# Create chain\n","chain = prompt | llm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zthz756JVWti","outputId":"0d16a829-29cf-4cda-8780-36305a74c1a9"},"outputs":[{"data":{"text/plain":["'The capital of the United States of America is Washington, D.C.'"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Replace the country variable with a value of your choice\n","chain.invoke(\"United States of America\").content"]},{"cell_type":"markdown","metadata":{"id":"8GNlBHSnVWtj"},"source":["### 方法二：一次性建立 ```PromptTemplate``` 物件和提示\n","明確指定 ```input_variables``` 以進行額外驗證。\n","否則，這些變數與模板字串中的變數不匹配可能會在實例化時引發異常。\n","\n","---\n","\n","## 我的見解\n","\n","明確指定 ```input_variables``` 是一個重要的最佳實務，它提供了額外的安全性和可讀性，特別是在複雜的生產環境中。\n","\n","## 學習補充重點\n","\n","**```input_variables``` 的重要性：**\n","\n","**驗證機制：**\n","- **變數一致性檢查**：確保模板中的變數與宣告的一致\n","- **錯誤提前發現**：在實例化階段就捕獲問題，而非執行時\n","- **型別安全**：提供更好的開發時檢查\n","\n","**範例說明：**\n","```python\n","# 正確的做法\n","prompt = PromptTemplate(\n","    input_variables=[\"topic\", \"level\"],\n","    template=\"解釋 {topic} 給 {level} 程度的學習者\"\n",")\n","\n","# 錯誤示範 - 變數不匹配\n","prompt = PromptTemplate(\n","    input_variables=[\"topic\"],  # 遺漏了 'level'\n","    template=\"解釋 {topic} 給 {level} 程度的學習者\"\n","    # 這會引發 ValueError\n",")\n","```\n","\n","**常見錯誤類型：**\n","- **遺漏變數**：模板中有變數但未在 input_variables 中宣告\n","- **多餘變數**：input_variables 中有變數但模板中未使用\n","- **變數名稱錯誤**：拼寫錯誤導致的不匹配\n","\n","**最佳實務建議：**\n","- **始終明確宣告**：即使 LangChain 可以自動推斷\n","- **使用描述性名稱**：讓變數用途一目了然\n","- **文檔化複雜變數**：為複雜的變數添加註釋\n","- **單元測試**：測試模板的各種輸入組合\n","\n","**進階配置選項：**\n","```python\n","prompt = PromptTemplate(\n","    input_variables=[\"topic\", \"level\"],\n","    template=\"解釋 {topic} 給 {level} 程度的學習者\",\n","    validate_template=True,  # 啟用嚴格驗證\n","    template_format=\"f-string\"  # 指定格式\n",")\n","```\n","\n","**除錯技巧：**\n","- 檢查變數名稱的拼寫\n","- 確認大括號語法正確\n","- 使用 IDE 的語法高亮協助檢查\n","- 建立測試案例驗證模板行為\n","\n","這種明確的方法雖然需要更多程式碼，但能大幅提高程式碼的可靠性和可維護性。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bEab7P_TVWtj","outputId":"dae03376-67f5-4103-8425-603839b58afc"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["# Define template\n","template = \"What is the capital of {country}?\"\n","\n","# Create a prompt template with `PromptTemplate` object\n","prompt = PromptTemplate(\n","    template=template,\n","    input_variables=[\"country\"],\n",")\n","prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ks9koRitVWtj","outputId":"4112eb8c-d3b3-4c02-dce8-65e827019ed4"},"outputs":[{"data":{"text/plain":["'What is the capital of United States of America?'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Create prompt\n","prompt.format(country=\"United States of America\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w830jCDLVWtj","outputId":"7055cd10-1aba-4187-f4d2-a7a277155c17"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': 'United States of America'}, template='What are the capitals of {country1} and {country2}, respectively?')"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Define template\n","template = \"What are the capitals of {country1} and {country2}, respectively?\"\n","\n","# Create a prompt template with `PromptTemplate` object\n","prompt = PromptTemplate(\n","    template=template,\n","    input_variables=[\"country1\"],\n","    partial_variables={\n","        \"country2\": \"United States of America\"  # Pass `partial_variables` in dictionary form\n","    },\n",")\n","prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j_uvJc3ZVWtj","outputId":"aefca3b6-0c34-4f7d-f7e6-574f709c73fa"},"outputs":[{"data":{"text/plain":["'What are the capitals of South Korea and United States of America, respectively?'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["prompt.format(country1=\"South Korea\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4h0FD0xRVWtj","outputId":"2fc6e068-451b-4a5e-f06c-3b33f4e8da55"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['country1'], input_types={}, partial_variables={'country2': 'India'}, template='What are the capitals of {country1} and {country2}, respectively?')"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["prompt_partial = prompt.partial(country2=\"India\")\n","prompt_partial"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7o8yi9zPVWtj","outputId":"fef468c8-fdbc-4a9a-8fcb-e1280bcbff30"},"outputs":[{"data":{"text/plain":["'What are the capitals of South Korea and India, respectively?'"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["prompt_partial.format(country1=\"South Korea\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"29NKYVr2VWtj"},"outputs":[],"source":["chain = prompt_partial | llm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a_X9Ul9jVWtj","outputId":"197a6482-26f1-4d95-9d65-0c3660a4be7c"},"outputs":[{"data":{"text/plain":["'The capital of the United States of America is Washington, D.C., and the capital of India is New Delhi.'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke(\"United States of America\").content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZMM3zB6VWtk","outputId":"759c6ab7-75fc-47a2-ba0a-62c976e791bc"},"outputs":[{"data":{"text/plain":["'The capital of the United States of America is Washington, D.C., and the capital of India is New Delhi.'"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"country1\": \"United States of America\", \"country2\": \"India\"}).content"]},{"cell_type":"markdown","metadata":{"id":"MTkvrjSfVWtk"},"source":["## 使用 ```partial_variables```\n","使用 ```partial_variables```，您可以部分應用函式。這在有**共用變數**需要分享時特別有用。\n","常見的範例是**日期或時間**。\n","假設您想在提示中指定當前日期，將日期硬編碼到提示中或與其他輸入變數一起傳遞可能不太實用。在這種情況下，使用返回當前日期的函式來部分修改提示會更加方便。\n","\n","---\n","\n","## 我的見解\n","\n","```partial_variables``` 是提示模板中非常實用的功能，它解決了動態值（如時間、系統資訊）與靜態模板結合的問題，大幅提升了模板的靈活性和實用性。\n","\n","## 學習補充重點\n","\n","**```partial_variables``` 的核心價值：**\n","\n","**動態內容處理：**\n","- **時間資訊**：當前日期、時間戳、時區資訊\n","- **系統資訊**：用戶 ID、會話 ID、應用版本\n","- **上下文資訊**：地理位置、語言設定、權限級別\n","\n","**使用方式：**\n","```python\n","from datetime import datetime\n","from langchain.prompts import PromptTemplate\n","\n","def get_current_date():\n","    return datetime.now().strftime(\"%Y-%m-%d\")\n","\n","# 使用函式作為部分變數\n","prompt = PromptTemplate(\n","    input_variables=[\"task\"],\n","    template=\"今天是 {date}，請幫我完成以下任務：{task}\",\n","    partial_variables={\"date\": get_current_date}\n",")\n","\n","# 或者使用固定值\n","prompt = PromptTemplate(\n","    input_variables=[\"query\"],\n","    template=\"系統版本：{version}\\n用戶查詢：{query}\",\n","    partial_variables={\"version\": \"v2.1.0\"}\n",")\n","```\n","\n","**實際應用場景：**\n","\n","**商業應用：**\n","- **報告生成**：自動插入報告日期和時間\n","- **個人化內容**：根據用戶資訊客製化訊息\n","- **合規要求**：自動記錄操作時間和版本資訊\n","\n","**技術應用：**\n","- **日誌記錄**：統一的時間戳格式\n","- **API 文檔**：動態插入當前 API 版本\n","- **測試環境**：區分不同環境的配置資訊\n","\n","**進階技巧：**\n","\n","**條件式部分變數：**\n","```python\n","def get_greeting():\n","    hour = datetime.now().hour\n","    if hour < 12:\n","        return \"早安\"\n","    elif hour < 18:\n","        return \"午安\"\n","    else:\n","        return \"晚安\"\n","\n","prompt = PromptTemplate(\n","    input_variables=[\"name\"],\n","    template=\"{greeting}，{name}！有什麼我可以幫助您的嗎？\",\n","    partial_variables={\"greeting\": get_greeting}\n",")\n","```\n","\n","**組合多個部分變數：**\n","```python\n","prompt = PromptTemplate(\n","    input_variables=[\"question\"],\n","    template=\"\"\"\n","    時間：{timestamp}\n","    系統：{system_info}\n","    用戶問題：{question}\n","    \n","    請根據上述資訊提供回答。\n","    \"\"\",\n","    partial_variables={\n","        \"timestamp\": lambda: datetime.now().isoformat(),\n","        \"system_info\": lambda: \"AI助手 v3.0\"\n","    }\n",")\n","```\n","\n","**最佳實務建議：**\n","- **快取機制**：對於成本較高的函式，考慮添加快取\n","- **錯誤處理**：確保部分變數函式的健壯性\n","- **性能考量**：避免在部分變數中執行耗時操作\n","- **測試覆蓋**：為部分變數函式建立單元測試\n","\n","**常見陷阱與解決方案：**\n","- **時區問題**：確保時間函式使用正確的時區\n","- **格式一致性**：統一日期時間格式\n","- **函式純度**：避免副作用，確保函式的可預測性\n","\n","```partial_variables``` 讓模板變得更加動態和智能，是建立專業級 AI 應用的重要工具。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JTxKYu_HVWtk","outputId":"7bd395a8-c23d-40ea-8b29-eb0d22675e9c"},"outputs":[{"data":{"text/plain":["'January 14'"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from datetime import datetime\n","\n","# Print the current date\n","datetime.now().strftime(\"%B %d\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uvlXGtH7VWtk"},"outputs":[],"source":["# Define function to return the current date\n","def get_today():\n","    return datetime.now().strftime(\"%B %d\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pi0uC_LbVWtk"},"outputs":[],"source":["prompt = PromptTemplate(\n","    template=\"Today's date is {today}. Please list {n} celebrities whose birthday is today. Please specify their date of birth.\",\n","    input_variables=[\"n\"],\n","    partial_variables={\n","        \"today\": get_today  # Pass `partial_variables` in dictionary form\n","    },\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3hn05msxVWtk","outputId":"36756856-84bd-467f-89b6-f9dbe17c51b4"},"outputs":[{"data":{"text/plain":["\"Today's date is January 14. Please list 3 celebrities whose birthday is today. Please specify their date of birth.\""]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Create prompt\n","prompt.format(n=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ka3WXlgBVWtk"},"outputs":[],"source":["# Create chain\n","chain = prompt | llm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JMoyt88DVWtk","outputId":"2a1891d6-f5a7-4e7d-bfa0-d30b4dd03fdb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Here are three celebrities born on January 14:\n","\n","1. **Dave Grohl** - Born on January 14, 1969.\n","2. **LL Cool J** - Born on January 14, 1968.\n","3. **Jason Bateman** - Born on January 14, 1969.\n"]}],"source":["# Invoke chain and check the result\n","print(chain.invoke(3).content)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4SDB_BPVWtk","outputId":"e50b160f-c363-4c66-c1ef-bf53436f526b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Here are three celebrities born on January 2:\n","\n","1. **Cuba Gooding Jr.** - Born on January 2, 1968.\n","2. **Taye Diggs** - Born on January 2, 1971.\n","3. **Kate Bosworth** - Born on January 2, 1983.\n"]}],"source":["# Invoke chain and check the result\n","print(chain.invoke({\"today\": \"Jan 02\", \"n\": 3}).content)"]},{"cell_type":"markdown","metadata":{"id":"vxSTXp6bVWtk"},"source":["## Load Prompt Templates from YAML Files\n","\n","You can manage prompt templates in seperate yaml files and load using ```load_prompt``` ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KQG6geJ-VWtl","outputId":"1a292d51-df2f-4e9c-855b-0e3a30da4674"},"outputs":[{"data":{"text/plain":["PromptTemplate(input_variables=['fruit'], input_types={}, partial_variables={}, template='What is the color of {fruit}?')"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.prompts import load_prompt\n","\n","prompt = load_prompt(\"prompts/fruit_color.yaml\", encoding=\"utf-8\")\n","prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG5T9A6qVWtm","outputId":"88b9398b-5f46-4b9c-b3e0-34ee33ad3148"},"outputs":[{"data":{"text/plain":["'What is the color of an apple?'"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["prompt.format(fruit=\"an apple\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O9KHxOvpVWtm","outputId":"441fbca1-1651-41a1-b07e-e1c918d57059"},"outputs":[{"name":"stdout","output_type":"stream","text":["Please provide information about the capital city of United States of America.\n","Summarize the characteristics of the capital in the following format, within 300 words.\n","----\n","[Format]\n","1. Area\n","2. Population\n","3. Historical Sites\n","4. Regional Products\n","\n","#Answer:\n","\n"]}],"source":["prompt2 = load_prompt(\"prompts/capital.yaml\")\n","print(prompt2.format(country=\"United States of America\"))"]},{"cell_type":"markdown","metadata":{"id":"XUC1vLXsVWtm"},"source":["## ```ChatPromptTemplate```\n","```ChatPromptTemplate``` 可用於將對話歷史記錄包含為提示。\n","訊息以元組格式 (```role```, ```message```) 結構化，並建立為清單。\n","**角色**\n","- ```system```：系統設定訊息，通常用於全域設定相關的提示。\n","- ```human```：使用者輸入訊息。\n","- ```ai```：AI 回應訊息。\n","\n","---\n","\n","## 我的見解\n","\n","```ChatPromptTemplate``` 是處理多輪對話的強大工具，它提供了結構化的方式來管理不同角色的訊息，這對於建立自然且上下文感知的對話系統至關重要。\n","\n","## 學習補充重點\n","\n","**```ChatPromptTemplate``` 的核心優勢：**\n","\n","**角色區分系統：**\n","- **清晰的對話結構**：明確區分不同參與者的訊息\n","- **上下文保持**：維持完整的對話歷史記錄\n","- **角色一致性**：確保每個角色的特性和行為一致\n","\n","**三種核心角色詳解：**\n","\n","**```system``` 角色：**\n","```python\n","from langchain.prompts import ChatPromptTemplate\n","\n","# 系統角色設定 AI 的行為和個性\n","messages = [\n","    (\"system\", \"你是一個專業的程式設計導師，請用清晰易懂的方式回答問題。\"),\n","    (\"human\", \"什麼是遞迴？\"),\n","    (\"ai\", \"遞迴是一種程式設計技巧...\"),\n","    (\"human\", \"可以給我一個範例嗎？\")\n","]\n","\n","chat_prompt = ChatPromptTemplate.from_messages(messages)\n","```\n","\n","**```human``` 角色：**\n","- 代表使用者的輸入和查詢\n","- 可以包含問題、指令或對話內容\n","- 通常是觸發 AI 回應的起點\n","\n","**```ai``` 角色：**\n","- 代表 AI 助手的回應\n","- 用於建立對話歷史記錄\n","- 提供上下文供後續互動參考\n","\n","**實際應用模式：**\n","\n","**客服對話系統：**\n","```python\n","chat_template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"你是一個客服代表，友善且專業地幫助客戶解決問題。\"),\n","    (\"human\", \"我的訂單還沒收到\"),\n","    (\"ai\", \"很抱歉聽到這個問題，讓我幫您查詢訂單狀態。\"),\n","    (\"human\", \"訂單號碼是 {order_number}\")\n","])\n","```\n","\n","**教育輔導系統：**\n","```python\n","education_template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"你是一位耐心的數學老師，用循序漸進的方式教學。\"),\n","    (\"human\", \"我不懂二次方程式\"),\n","    (\"ai\", \"沒關係，我們從基礎開始學習...\"),\n","    (\"human\", \"{new_question}\")\n","])\n","```\n","\n","**動態對話建構：**\n","```python\n","def build_chat_history(conversation_history, new_message):\n","    messages = [(\"system\", \"你是一個有用的助手\")]\n","    \n","    # 添加歷史對話\n","    for turn in conversation_history:\n","        messages.append((\"human\", turn[\"user\"]))\n","        messages.append((\"ai\", turn[\"assistant\"]))\n","    \n","    # 添加新訊息\n","    messages.append((\"human\", new_message))\n","    \n","    return ChatPromptTemplate.from_messages(messages)\n","```\n","\n","**進階技巧：**\n","\n","**條件式訊息：**\n","```python\n","def create_conditional_chat(user_type, query):\n","    if user_type == \"expert\":\n","        system_msg = \"請提供技術深度的專業回答\"\n","    else:\n","        system_msg = \"請用簡單易懂的方式回答\"\n","    \n","    return ChatPromptTemplate.from_messages([\n","        (\"system\", system_msg),\n","        (\"human\", query)\n","    ])\n","```\n","\n","**模板變數整合：**\n","```python\n","chat_template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"你是專精於 {domain} 的專家\"),\n","    (\"human\", \"關於 {topic} 的問題：{question}\")\n","])\n","\n","# 使用時填入變數\n","formatted = chat_template.format_messages(\n","    domain=\"機器學習\",\n","    topic=\"神經網路\",\n","    question=\"什麼是反向傳播？\"\n",")\n","```\n","\n","**最佳實務建議：**\n","- **角色一致性**：確保每個角色的語調和風格一致\n","- **適當的系統提示**：清楚定義 AI 的行為和限制\n","- **對話長度管理**：避免對話歷史過長影響效能\n","- **上下文相關性**：只保留與當前對話相關的歷史記錄\n","\n","```ChatPromptTemplate``` 是建立高品質對話系統的基礎工具，它讓開發者能夠創建更自然、更有上下文感知能力的 AI 互動體驗。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J4c6f5MRVWtm","outputId":"aee66d58-f612-4f22-c2fe-d7eaa3fe969a"},"outputs":[{"data":{"text/plain":["ChatPromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?'), additional_kwargs={})])"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","chat_prompt = ChatPromptTemplate.from_template(\"What is the capital of {country}?\")\n","chat_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RmTAL202VWtm","outputId":"4ed3c229-a38c-4786-9322-ef7a5ac624ee"},"outputs":[{"data":{"text/plain":["'Human: What is the capital of United States of America?'"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["chat_prompt.format(country=\"United States of America\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Po4s4E2VWtm","outputId":"6a2915c5-41c4-4969-eee5-9e4ea0e0b0ee"},"outputs":[{"data":{"text/plain":["[SystemMessage(content='You are a friendly AI assistant. Your name is Teddy.', additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='Nice to meet you!', additional_kwargs={}, response_metadata={}),\n"," AIMessage(content='Hello! How can I assist you?', additional_kwargs={}, response_metadata={}),\n"," HumanMessage(content='What is your name?', additional_kwargs={}, response_metadata={})]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","chat_template = ChatPromptTemplate.from_messages(\n","    [\n","        # role, message\n","        (\"system\", \"You are a friendly AI assistant. Your name is {name}.\"),\n","        (\"human\", \"Nice to meet you!\"),\n","        (\"ai\", \"Hello! How can I assist you?\"),\n","        (\"human\", \"{user_input}\"),\n","    ]\n",")\n","\n","# Create chat messages\n","messages = chat_template.format_messages(name=\"Teddy\", user_input=\"What is your name?\")\n","messages"]},{"cell_type":"markdown","metadata":{"id":"Q47shXh-VWtm"},"source":["You can directly invoke LLM using the messages created above."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bjjLw1WlVWtn","outputId":"dc09aa96-8d69-4308-8540-868353dc2e58"},"outputs":[{"data":{"text/plain":["'My name is Teddy. How can I help you today?'"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["llm.invoke(messages).content"]},{"cell_type":"markdown","metadata":{"id":"yTMKtF2kVWtn"},"source":["You can also create a chain to execute."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5A2JtS5OVWtn"},"outputs":[],"source":["chain = chat_template | llm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MhPHZZXVVWtn","outputId":"a53c2333-147a-4ce2-a25d-c728595db9ac"},"outputs":[{"data":{"text/plain":["'My name is Teddy. How can I help you today?'"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["chain.invoke({\"name\": \"Teddy\", \"user_input\": \"What is your name?\"}).content"]},{"cell_type":"markdown","metadata":{"id":"hJJgeuYbVWtn"},"source":["## ```ChatPromptTemplate```\n","```ChatPromptTemplate``` 可用於將對話歷史記錄包含為提示。\n","訊息以元組格式 (```role```, ```message```) 結構化，並建立為清單。\n","**角色**\n","- ```system```：系統設定訊息，通常用於全域設定相關的提示。\n","- ```human```：使用者輸入訊息。\n","- ```ai```：AI 回應訊息。\n","\n","---\n","\n","## 我的見解\n","\n","```ChatPromptTemplate``` 是處理多輪對話的強大工具，它提供了結構化的方式來管理不同角色的訊息，這對於建立自然且上下文感知的對話系統至關重要。\n","\n","## 學習補充重點\n","\n","**```ChatPromptTemplate``` 的核心優勢：**\n","\n","**角色區分系統：**\n","- **清晰的對話結構**：明確區分不同參與者的訊息\n","- **上下文保持**：維持完整的對話歷史記錄\n","- **角色一致性**：確保每個角色的特性和行為一致\n","\n","**三種核心角色詳解：**\n","\n","**```system``` 角色：**\n","```python\n","from langchain.prompts import ChatPromptTemplate\n","\n","# 系統角色設定 AI 的行為和個性\n","messages = [\n","    (\"system\", \"你是一個專業的程式設計導師，請用清晰易懂的方式回答問題。\"),\n","    (\"human\", \"什麼是遞迴？\"),\n","    (\"ai\", \"遞迴是一種程式設計技巧...\"),\n","    (\"human\", \"可以給我一個範例嗎？\")\n","]\n","\n","chat_prompt = ChatPromptTemplate.from_messages(messages)\n","```\n","\n","**```human``` 角色：**\n","- 代表使用者的輸入和查詢\n","- 可以包含問題、指令或對話內容\n","- 通常是觸發 AI 回應的起點\n","\n","**```ai``` 角色：**\n","- 代表 AI 助手的回應\n","- 用於建立對話歷史記錄\n","- 提供上下文供後續互動參考\n","\n","**實際應用模式：**\n","\n","**客服對話系統：**\n","```python\n","chat_template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"你是一個客服代表，友善且專業地幫助客戶解決問題。\"),\n","    (\"human\", \"我的訂單還沒收到\"),\n","    (\"ai\", \"很抱歉聽到這個問題，讓我幫您查詢訂單狀態。\"),\n","    (\"human\", \"訂單號碼是 {order_number}\")\n","])\n","```\n","\n","**教育輔導系統：**\n","```python\n","education_template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"你是一位耐心的數學老師，用循序漸進的方式教學。\"),\n","    (\"human\", \"我不懂二次方程式\"),\n","    (\"ai\", \"沒關係，我們從基礎開始學習...\"),\n","    (\"human\", \"{new_question}\")\n","])\n","```\n","\n","**動態對話建構：**\n","```python\n","def build_chat_history(conversation_history, new_message):\n","    messages = [(\"system\", \"你是一個有用的助手\")]\n","    \n","    # 添加歷史對話\n","    for turn in conversation_history:\n","        messages.append((\"human\", turn[\"user\"]))\n","        messages.append((\"ai\", turn[\"assistant\"]))\n","    \n","    # 添加新訊息\n","    messages.append((\"human\", new_message))\n","    \n","    return ChatPromptTemplate.from_messages(messages)\n","```\n","\n","**進階技巧：**\n","\n","**條件式訊息：**\n","```python\n","def create_conditional_chat(user_type, query):\n","    if user_type == \"expert\":\n","        system_msg = \"請提供技術深度的專業回答\"\n","    else:\n","        system_msg = \"請用簡單易懂的方式回答\"\n","    \n","    return ChatPromptTemplate.from_messages([\n","        (\"system\", system_msg),\n","        (\"human\", query)\n","    ])\n","```\n","\n","**模板變數整合：**\n","```python\n","chat_template = ChatPromptTemplate.from_messages([\n","    (\"system\", \"你是專精於 {domain} 的專家\"),\n","    (\"human\", \"關於 {topic} 的問題：{question}\")\n","])\n","\n","# 使用時填入變數\n","formatted = chat_template.format_messages(\n","    domain=\"機器學習\",\n","    topic=\"神經網路\",\n","    question=\"什麼是反向傳播？\"\n",")\n","```\n","\n","**最佳實務建議：**\n","- **角色一致性**：確保每個角色的語調和風格一致\n","- **適當的系統提示**：清楚定義 AI 的行為和限制\n","- **對話長度管理**：避免對話歷史過長影響效能\n","- **上下文相關性**：只保留與當前對話相關的歷史記錄\n","\n","```ChatPromptTemplate``` 是建立高品質對話系統的基礎工具，它讓開發者能夠創建更自然、更有上下文感知能力的 AI 互動體驗。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l6F5iOExVWtn","outputId":"46f0ce54-9c63-4e00-dec4-e6b5444b6aa3"},"outputs":[{"data":{"text/plain":["ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000020B148D7E20>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a summarization specialist AI assistant. Your mission is to summarize conversations using key points.'), additional_kwargs={}), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='Summarize the conversation so far in {word_count} words.'), additional_kwargs={})])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n","\n","chat_prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"You are a summarization specialist AI assistant. Your mission is to summarize conversations using key points.\",\n","        ),\n","        MessagesPlaceholder(variable_name=\"conversation\"),\n","        (\"human\", \"Summarize the conversation so far in {word_count} words.\"),\n","    ]\n",")\n","chat_prompt"]},{"cell_type":"markdown","metadata":{"id":"itsH3zbHVWtn"},"source":["You can use ```MessagesPlaceholder``` to add the conversation message list."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GaTnMy-VVWtn","outputId":"48f53a77-2d02-47a0-e531-f9d7b8b7bb17"},"outputs":[{"name":"stdout","output_type":"stream","text":["System: You are a summarization specialist AI assistant. Your mission is to summarize conversations using key points.\n","Human: Hello! I’m Teddy. Nice to meet you.\n","AI: Nice to meet you! I look forward to working with you.\n","Human: Summarize the conversation so far in 5 words.\n"]}],"source":["formatted_chat_prompt = chat_prompt.format(\n","    word_count=5,\n","    conversation=[\n","        (\"human\", \"Hello! I’m Teddy. Nice to meet you.\"),\n","        (\"ai\", \"Nice to meet you! I look forward to working with you.\"),\n","    ],\n",")\n","\n","print(formatted_chat_prompt)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_a5JWWVrVWto"},"outputs":[],"source":["# Create chain\n","chain = chat_prompt | llm | StrOutputParser()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PI2lZShPVWto","outputId":"a30ee0f2-9e56-4ba4-ad60-97f42551d151"},"outputs":[{"data":{"text/plain":["'Teddy introduces himself, exchanges greetings.'"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["# Invoke chain and check the result\n","chain.invoke(\n","    {\n","        \"word_count\": 5,\n","        \"conversation\": [\n","            (\n","                \"human\",\n","                \"Hello! I'm Teddy. Nice to meet you.\",\n","            ),\n","            (\"ai\", \"Nice to meet you! I look forward to working with you.\"),\n","        ],\n","    }\n",")"]}],"metadata":{"kernelspec":{"display_name":"langchain-kr-ARohChI8-py3.11","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}